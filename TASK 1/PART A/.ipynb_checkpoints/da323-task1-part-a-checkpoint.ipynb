{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Dataset Collection Project\n",
    "- **Objective:**  Automate the collection of images from Google Images for 20 predefined categories,\n",
    "  download 50 images per category, store metadata, and organize them into labeled folders.\n",
    " \n",
    "## **Dataset Name:** `ImageDataset`\n",
    "\n",
    "### **Use Case:**\n",
    "- This dataset can be used to train and evaluate image classification models.\n",
    "- For example, you can build a convolutional neural network that learns to distinguish between different\n",
    "  categories such as \"Nature\", \"Animals\", \"Cars\", etc.\n",
    "- The metadata (image URL, filename, and resolution) can be used during preprocessing (e.g., resizing, augmentation) before training your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries \n",
    "- We import libraries for web automation (Selenium), HTTP requests, HTML parsing (BeautifulSoup),image processing (Pillow), and OS/file operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:41:25.191415Z",
     "iopub.status.busy": "2025-03-08T06:41:25.191134Z",
     "iopub.status.idle": "2025-03-08T06:41:31.407654Z",
     "shell.execute_reply": "2025-03-08T06:41:31.406558Z",
     "shell.execute_reply.started": "2025-03-08T06:41:25.191394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 selenium-4.29.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:41:34.824992Z",
     "iopub.status.busy": "2025-03-08T06:41:34.824523Z",
     "iopub.status.idle": "2025-03-08T06:41:34.828750Z",
     "shell.execute_reply": "2025-03-08T06:41:34.828008Z",
     "shell.execute_reply.started": "2025-03-08T06:41:34.824931Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "from io import BytesIO\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Categories and Create Folders\n",
    "- We define a list of 20 categories and then create a base directory (`ImageDataset`) with one subfolder per category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:41:37.050907Z",
     "iopub.status.busy": "2025-03-08T06:41:37.050637Z",
     "iopub.status.idle": "2025-03-08T06:41:37.056974Z",
     "shell.execute_reply": "2025-03-08T06:41:37.056309Z",
     "shell.execute_reply.started": "2025-03-08T06:41:37.050886Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"Nature\", \"Animals\", \"Cars\", \"Flowers\", \"Mountains\", \"Beaches\", \"Food\", \"Architecture\",\n",
    "    \"Sports\", \"Fashion\", \"Technology\", \"Art\", \"Cityscapes\", \"Insects\", \"Birds\",\n",
    "    \"Underwater\", \"Landscapes\", \"Urban\", \"Space\", \"Portraits\"\n",
    "]\n",
    "\n",
    "# Create base directory for the dataset\n",
    "base_dir = \"ImageDataset\"\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "# Create subfolders for each category\n",
    "for cat in categories:\n",
    "    cat_dir = os.path.join(base_dir, cat)\n",
    "    if not os.path.exists(cat_dir):\n",
    "        os.makedirs(cat_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setup Selenium WebDriver\n",
    "- We configure the Selenium WebDriver to run in headless mode for automation.\n",
    "- **Make sure** that the ChromeDriver is installed and available in your system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Create a temporary directory for Chrome user data\n",
    "temp_user_data_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Setup Chrome WebDriver options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # run in headless mode\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(f\"--user-data-dir={temp_user_data_dir}\")  # Use a unique user data directory\n",
    "\n",
    "# Initialize the driver (ensure 'chromedriver' is in your PATH)\n",
    "driver = webdriver.Chrome(options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define a Function to Download Images for a Category\n",
    "\n",
    "-  **The function `download_images_for_category` will:**\n",
    "     - Open a Google Images search page for the given category.\n",
    "     - Scroll down a few times to load more images.\n",
    "     - Parse the page with BeautifulSoup to extract image URLs.\n",
    "     - Download up to 50 images.\n",
    "     - Save each image in its respective category folder.\n",
    "     - Extract image resolution using Pillow.\n",
    "     - Return metadata for all downloaded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images_for_category(category, num_images=50):\n",
    "    query = category\n",
    "    # Construct the Google Images search URL (using the \"tbm=isch\" parameter)\n",
    "    search_url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "    \n",
    "    # Scroll to load more images (adjust the range as needed)\n",
    "    for i in range(3):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Parse the page source using BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    image_elements = soup.find_all(\"img\")\n",
    "    print(f\"Found {len(image_elements)} image elements for '{category}'.\")\n",
    "    \n",
    "    downloaded = 0\n",
    "    metadata = []\n",
    "    for idx, img in enumerate(image_elements):\n",
    "        if downloaded >= num_images:\n",
    "            break\n",
    "        img_url = img.get(\"src\")\n",
    "        if img_url is None:\n",
    "            continue  # Skip if no URL is found\n",
    "        try:\n",
    "            # Download the image data\n",
    "            response = requests.get(img_url, timeout=10)\n",
    "            img_data = response.content\n",
    "            \n",
    "            # Open the image with Pillow to get its resolution\n",
    "            image = Image.open(BytesIO(img_data))\n",
    "            width, height = image.size\n",
    "            \n",
    "            # Define a filename and save the image in the corresponding folder\n",
    "            filename = f\"{category}_{downloaded+1}.jpg\"\n",
    "            file_path = os.path.join(base_dir, category, filename)\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(img_data)\n",
    "            \n",
    "            # Append metadata info\n",
    "            metadata.append({\n",
    "                \"category\": category,\n",
    "                \"image_url\": img_url,\n",
    "                \"filename\": filename,\n",
    "                \"resolution\": f\"{width}x{height}\"\n",
    "            })\n",
    "            \n",
    "            downloaded += 1\n",
    "            print(f\"Downloaded: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading image {idx} for '{category}': {e}\")\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Download Images for All Categories and Save Metadata to CSV\n",
    "- For each category, we call the `download_images_for_category` function.\n",
    "-  Then, we combine all metadata and save it into a CSV file for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metadata = []\n",
    "for cat in categories:\n",
    "    print(f\"\\nProcessing category: {cat}\")\n",
    "    cat_metadata = download_images_for_category(cat, num_images=50)\n",
    "    all_metadata.extend(cat_metadata)\n",
    "\n",
    "# Save all metadata to a CSV file\n",
    "csv_filename = os.path.join(base_dir, \"metadata.csv\")\n",
    "with open(csv_filename, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\"category\", \"image_url\", \"filename\", \"resolution\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for data in all_metadata:\n",
    "        writer.writerow(data)\n",
    "\n",
    "print(f\"\\nMetadata saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Clean Up\n",
    "- After downloading the images, we close the Selenium WebDriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Use Case\n",
    "\n",
    "### **Dataset Name:** `ImageDataset`\n",
    " \n",
    "### **Description:** \n",
    "- This dataset consists of images from 20 different categories (e.g., Nature, Animals, Cars, etc.), with 50 images per category.\n",
    "- All images are stored in labeled folders, and the accompanying CSV file contains metadata such as the image URL, filename, and resolution.\n",
    "\n",
    "### **Use Case:** \n",
    "-The dataset is ideal for training image classification models using deep learning. Researchers and developers can utilize this curated data to build and evaluate convolutional neural networks (CNNs) that automatically classify images into their respective categories. The metadata can assist in preprocessing tasks like resizing or augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
